{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import tifffile\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Conv2D, Reshape, Input, Conv2DTranspose\n",
    "from keras.layers import Activation, LeakyReLU, BatchNormalization, Dropout, Resizing\n",
    "import dcgan as dcgan\n",
    "import wgan as wgan\n",
    "import prgan as prgan\n",
    "\n",
    "from fid_score import calculate_fid\n",
    "from fid_score import preprocess_array\n",
    "\n",
    "try:\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "except:\n",
    "    from keras.optimizers import Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_DIM = 100  \n",
    "BATCH_SIZE = 20 \n",
    "STEPS_PER_EPOCH = 100\n",
    "EPOCHS = 2\n",
    "STEPS = 1\n",
    "SEED = 40\n",
    "WIDTH, HEIGHT, CHANNELS = 75, 75, 2\n",
    "OPTIMIZER = Adam(0.0002, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('./data/train.json')\n",
    "train['inc_angle'] = pd.to_numeric(train['inc_angle'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(train,label=1):\n",
    "    train['max'+str(label)] = [np.max(np.array(x)) for x in train['band_'+str(label)] ]\n",
    "    train['maxpos'+str(label)] = [np.argmax(np.array(x)) for x in train['band_'+str(label)] ]\n",
    "    train['min'+str(label)] = [np.min(np.array(x)) for x in train['band_'+str(label)] ]\n",
    "    train['minpos'+str(label)] = [np.argmin(np.array(x)) for x in train['band_'+str(label)] ]\n",
    "    train['med'+str(label)] = [np.median(np.array(x)) for x in train['band_'+str(label)] ]\n",
    "    train['std'+str(label)] = [np.std(np.array(x)) for x in train['band_'+str(label)] ]\n",
    "    train['mean'+str(label)] = [np.mean(np.array(x)) for x in train['band_'+str(label)] ]\n",
    "    train['p25_'+str(label)] = [np.sort(np.array(x))[int(0.25*75*75)] for x in train['band_'+str(label)] ]\n",
    "    train['p75_'+str(label)] = [np.sort(np.array(x))[int(0.75*75*75)] for x in train['band_'+str(label)] ]\n",
    "    train['mid50_'+str(label)] = train['p75_'+str(label)]-train['p25_'+str(label)]\n",
    "\n",
    "    return train\n",
    "train = get_stats(train,1)\n",
    "train = get_stats(train,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_var(name,nbins=50):\n",
    "    minval = train[name].min()\n",
    "    maxval = train[name].max()\n",
    "    plt.hist(train.loc[train.is_iceberg==1,name],range=[minval,maxval],\n",
    "             bins=nbins,color='b',alpha=0.5,label='Boat')\n",
    "    plt.hist(train.loc[train.is_iceberg==0,name],range=[minval,maxval],\n",
    "             bins=nbins,color='r',alpha=0.5,label='Iceberg')\n",
    "    plt.legend()\n",
    "    plt.xlim([minval,maxval])\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel('Number')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['inc_angle','min1','max1','std1','med1','mean1','mid50_1']:\n",
    "    plot_var(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = train.drop(['id','is_iceberg','band_1','band_2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train_stats.corr()\n",
    "fig = plt.figure(1, figsize=(10,10))\n",
    "plt.imshow(corr,cmap='inferno')\n",
    "labels = np.arange(len(train_stats.columns))\n",
    "plt.xticks(labels,train_stats.columns,rotation=90)\n",
    "plt.yticks(labels,train_stats.columns)\n",
    "plt.title('Correlation Matrix of Global Variables')\n",
    "cbar = plt.colorbar(shrink=0.85,pad=0.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icebergs = train[train.is_iceberg==1].sample(n=300,random_state=123)\n",
    "ships = train[train.is_iceberg==0].sample(n=300,random_state=456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot band_1/band_2 images\n",
    "fig = plt.figure(1,figsize=(15,15))\n",
    "for i in range(9):\n",
    "    ax = fig.add_subplot(3,3,i+1)\n",
    "    arr = np.reshape(np.array(icebergs.iloc[i,1]),(75,75))\n",
    "    ax.imshow(arr,cmap='inferno')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(images, n_cols=None):\n",
    "    '''Visualizes fake images'''\n",
    "\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1\n",
    "\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.squeeze(images, axis=-1)\n",
    "\n",
    "    plt.figure(figsize=(n_cols * 2, n_rows * 2))  # Increase the figure size to accommodate 2-band images\n",
    "\n",
    "    for index, image in enumerate(images):\n",
    "        if image.shape[-1] == 1:\n",
    "            image = np.squeeze(image, axis=-1)\n",
    "        elif image.shape[-1] == 2:\n",
    "            # Merge the two bands into a single image\n",
    "            image = np.dstack((image[:, :, 0], image[:, :, 1]))\n",
    "            image = np.mean(image, axis=2)  # Convert to grayscale by taking the mean of the two bands\n",
    "        else:\n",
    "            raise ValueError(\"Invalid number of image bands\")\n",
    "\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(image, cmap=\"inferno\")\n",
    "        plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the training images\n",
    "X_train = icebergs[['band_1', 'band_2']]\n",
    "# Remove the first row (column names)\n",
    "column_names = X_train.iloc[0]\n",
    "X_train = X_train.iloc[1:]\n",
    "\n",
    "column_1 = np.array([np.array(image) for image in X_train['band_1']])\n",
    "column_2 = np.array([np.array(image) for image in X_train['band_2']])\n",
    "\n",
    "column_1 = column_1.flatten().reshape(-1)\n",
    "column_2 = column_2.flatten().reshape(-1)\n",
    "\n",
    "mean_1 = np.mean(column_1)\n",
    "std_1 = np.std(column_1)\n",
    "\n",
    "mean_2 = np.mean(column_2)\n",
    "std_2 = np.std(column_2)\n",
    "\n",
    "normalized_column_1 = (column_1 - column_1.min()) / (column_1.max() - column_1.min())\n",
    "normalized_column_2 = (column_2 - column_2.min()) / (column_2.max() - column_2.min())\n",
    "#normalized_column_1 = (column_1 - mean_1) / std_1\n",
    "#normalized_column_2 = (column_2 - mean_2) / std_2\n",
    "\n",
    "X_train_normalized = np.column_stack((normalized_column_1, normalized_column_2))\n",
    "#print(X_train[0])\n",
    "# Reshape images \n",
    "X_train = X_train_normalized.reshape(-1, WIDTH,HEIGHT,CHANNELS)\n",
    "\n",
    "# Convert X_train to a NumPy array\n",
    "X_train_array = np.array(X_train)\n",
    "\n",
    "\n",
    "print(X_train_array.shape)\n",
    "\n",
    "# create batches of tensors to be fed into the model\n",
    "dataset = X_train\n",
    "print(X_train_array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(noise, subplots, generator, prefix, figsize=(22,8), save=False):\n",
    "    generated_images = generator.predict(noise)\n",
    "    plt.figure(figsize=figsize)\n",
    "    #print(np.amax(generated_images))\n",
    "    samples = []\n",
    "    for i, image in enumerate(generated_images):\n",
    "        plt.subplot(subplots[0], subplots[1], i+1)\n",
    "        if CHANNELS == 1:\n",
    "            plt.imshow(image.reshape((WIDTH, HEIGHT)), cmap='gray')    \n",
    "                                                                            \n",
    "        else:\n",
    "            image_band1 = np.reshape(np.array(image[:, :, 1]),(75,75))\n",
    "            plt.imshow(image_band1, cmap='inferno')\n",
    "\n",
    "            #channel_1 = image[:, :, 0]\n",
    "            #channel_2 = image[:, :, 1]\n",
    "\n",
    "            #plt.subplot(1, 2, 1)\n",
    "            #plt.imshow(channel_1, cmap='gray')\n",
    "            #plt.title('Channel 1')\n",
    "\n",
    "            #plt.subplot(1, 2, 2)\n",
    "            #plt.imshow(channel_2, cmap='gray')\n",
    "            #plt.title('Channel 2')\n",
    "\n",
    "            #plt.show()\n",
    "            import matplotlib.image\n",
    "            #print(np.amin(image.reshape((WIDTH, HEIGHT, 3))))\n",
    "            from skimage import util\n",
    "            #image = (image - image.min()) / (image.max() - image.min())\n",
    "            #print(np.min(image))   # minimum value of the image data\n",
    "            #print(np.max(image))   # maximum value of the image data\n",
    "            #matplotlib.image.imsave('gen_img'+str(i)+'.png', image)\n",
    "            #image_data = np.transpose(image, (2, 0, 1))\n",
    "            # Transpose the array to have shape (height, width, num_channels)\n",
    "            #image_data = np.transpose(image, (2, 0, 1))\n",
    "            #print(image.shape)\n",
    "            # Concatenate the channels along the third axis to create a multi-channel image\n",
    "            print(image.shape)\n",
    "            joined_channels_image = np.concatenate([np.expand_dims(image[:, :, i], axis=0) for i in range(image.shape[2])], axis=0)\n",
    "            joined_channels_image = np.transpose(joined_channels_image, (1, 2, 0))  # Transpose dimensions\n",
    "\n",
    "            samples.append(joined_channels_image)\n",
    "            combined_image = np.mean(joined_channels_image, axis=2)\n",
    "\n",
    "            plt.imshow(combined_image, cmap='inferno')\n",
    "            # Save grayscale image as PNG\n",
    "            plt.imsave(prefix + '_gen_img' + str(i) + '.png', combined_image, cmap='inferno')\n",
    "\n",
    "        if save == True:\n",
    "            img_name = \"gen\" + str(i)\n",
    "            plt.savefig(img_name)\n",
    "        plt.subplots_adjust(wspace=None, hspace=None)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models():\n",
    "    np.random.seed(SEED)\n",
    "    \n",
    "    noise_dcgan = np.random.normal(0,1, size=(BATCH_SIZE, NOISE_DIM))\n",
    "    noise_wgan = tf.random.normal([32, 75*75*2])\n",
    "    generator_dcgan, discriminator_dcgan, dcgan_model = dcgan.build(OPTIMIZER, NOISE_DIM)\n",
    "    generator_dcgan_loss_values = dcgan.train(generator_dcgan, discriminator_dcgan, dcgan_model, noise_dcgan, EPOCHS, STEPS, BATCH_SIZE, NOISE_DIM, X_train_array)\n",
    "    generator_wgan, generator_wgan_loss_values = wgan.train(EPOCHS, STEPS, BATCH_SIZE, NOISE_DIM, X_train_array)\n",
    "    generator_prgan, generator_prgan_loss_values = prgan.build(X_train_array)\n",
    "    \n",
    "    return generator_dcgan, generator_dcgan_loss_values, generator_wgan, generator_wgan_loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_dcgan, generator_dcgan_loss_values, generator_wgan, generator_wgan_loss_values = train_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the loss values for Model 1\n",
    "#plt.plot(discriminator_loss_model1, label='Model 1 - Discriminator Loss')\n",
    "plt.plot(generator_dcgan_loss_values, label='DCGAN')\n",
    "\n",
    "# Plotting the loss values for Model 2\n",
    "#plt.plot(discriminator_loss_model2, label='Model 2 - Discriminator Loss')\n",
    "plt.plot(generator_wgan_loss_values, label='WGAN')\n",
    "\n",
    "# Adding labels and title to the plot\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('GAN Loss Evolution')\n",
    "\n",
    "# Adding a legend\n",
    "plt.legend()\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dcgan = np.random.normal(0, 1, size=(100, NOISE_DIM))\n",
    "noise_wgan = tf.random.normal([32, 75*75*2])\n",
    "noise_prgan = tf.random.normal([32, 75*75*2])\n",
    "samples_dcgan = sample_images(noise_dcgan, (10,10), generator_dcgan, 'dcgan', (24,20), save=True)\n",
    "samples_wgan = sample_images(noise_wgan, (10,10), generator_wgan, 'wgan', (24,20), save=True)\n",
    "samples_wgan = sample_images(noise_prgan, (10,10), generator_prgan, 'wgan', (24,20), save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_dcgan_array = np.array(samples_dcgan)\n",
    "samples_wgan_array = np.array(samples_wgan)\n",
    "X_train_array = np.array(X_train)\n",
    "\n",
    "samples_dcgan_array = preprocess_array(samples_dcgan_array)\n",
    "samples_wgan_array = preprocess_array(samples_wgan_array)\n",
    "X_train_array = preprocess_array(X_train_array)\n",
    "\n",
    "print(calculate_fid(X_train_array[:10], samples_dcgan_array[:10]))\n",
    "print(calculate_fid(X_train_array[:10], samples_wgan_array[:10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
