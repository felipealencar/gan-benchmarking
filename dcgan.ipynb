{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import tifffile\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Conv2D, Reshape, Input, Conv2DTranspose\n",
    "from keras.layers import Activation, LeakyReLU, BatchNormalization, Dropout, Resizing\n",
    "try:\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "except:\n",
    "    from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_DIM = 100  \n",
    "BATCH_SIZE = 20 \n",
    "STEPS_PER_EPOCH = 100\n",
    "EPOCHS = 100\n",
    "SEED = 40\n",
    "WIDTH, HEIGHT, CHANNELS = 75, 75, 2\n",
    "\n",
    "OPTIMIZER = Adam(0.0002, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('./data/train.json')\n",
    "train['inc_angle'] = pd.to_numeric(train['inc_angle'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(train,label=1):\n",
    "    train['max'+str(label)] = [np.max(np.array(x)) for x in train['band_'+str(label)] ]\n",
    "    train['maxpos'+str(label)] = [np.argmax(np.array(x)) for x in train['band_'+str(label)] ]\n",
    "    train['min'+str(label)] = [np.min(np.array(x)) for x in train['band_'+str(label)] ]\n",
    "    train['minpos'+str(label)] = [np.argmin(np.array(x)) for x in train['band_'+str(label)] ]\n",
    "    train['med'+str(label)] = [np.median(np.array(x)) for x in train['band_'+str(label)] ]\n",
    "    train['std'+str(label)] = [np.std(np.array(x)) for x in train['band_'+str(label)] ]\n",
    "    train['mean'+str(label)] = [np.mean(np.array(x)) for x in train['band_'+str(label)] ]\n",
    "    train['p25_'+str(label)] = [np.sort(np.array(x))[int(0.25*75*75)] for x in train['band_'+str(label)] ]\n",
    "    train['p75_'+str(label)] = [np.sort(np.array(x))[int(0.75*75*75)] for x in train['band_'+str(label)] ]\n",
    "    train['mid50_'+str(label)] = train['p75_'+str(label)]-train['p25_'+str(label)]\n",
    "\n",
    "    return train\n",
    "train = get_stats(train,1)\n",
    "train = get_stats(train,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_var(name,nbins=50):\n",
    "    minval = train[name].min()\n",
    "    maxval = train[name].max()\n",
    "    plt.hist(train.loc[train.is_iceberg==1,name],range=[minval,maxval],\n",
    "             bins=nbins,color='b',alpha=0.5,label='Boat')\n",
    "    plt.hist(train.loc[train.is_iceberg==0,name],range=[minval,maxval],\n",
    "             bins=nbins,color='r',alpha=0.5,label='Iceberg')\n",
    "    plt.legend()\n",
    "    plt.xlim([minval,maxval])\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel('Number')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['inc_angle','min1','max1','std1','med1','mean1','mid50_1']:\n",
    "    plot_var(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = train.drop(['id','is_iceberg','band_1','band_2'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train_stats.corr()\n",
    "fig = plt.figure(1, figsize=(10,10))\n",
    "plt.imshow(corr,cmap='inferno')\n",
    "labels = np.arange(len(train_stats.columns))\n",
    "plt.xticks(labels,train_stats.columns,rotation=90)\n",
    "plt.yticks(labels,train_stats.columns)\n",
    "plt.title('Correlation Matrix of Global Variables')\n",
    "cbar = plt.colorbar(shrink=0.85,pad=0.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icebergs = train[train.is_iceberg==1].sample(n=300,random_state=123)\n",
    "ships = train[train.is_iceberg==0].sample(n=300,random_state=456)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot band_1/band_2 images\n",
    "fig = plt.figure(1,figsize=(15,15))\n",
    "for i in range(9):\n",
    "    ax = fig.add_subplot(3,3,i+1)\n",
    "    arr = np.reshape(np.array(icebergs.iloc[i,1]),(75,75))\n",
    "    ax.imshow(arr,cmap='inferno')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(images, n_cols=None):\n",
    "    '''Visualizes fake images'''\n",
    "\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1\n",
    "\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.squeeze(images, axis=-1)\n",
    "\n",
    "    plt.figure(figsize=(n_cols * 2, n_rows * 2))  # Increase the figure size to accommodate 2-band images\n",
    "\n",
    "    for index, image in enumerate(images):\n",
    "        if image.shape[-1] == 1:\n",
    "            image = np.squeeze(image, axis=-1)\n",
    "        elif image.shape[-1] == 2:\n",
    "            # Merge the two bands into a single image\n",
    "            image = np.dstack((image[:, :, 0], image[:, :, 1]))\n",
    "            image = np.mean(image, axis=2)  # Convert to grayscale by taking the mean of the two bands\n",
    "        else:\n",
    "            raise ValueError(\"Invalid number of image bands\")\n",
    "\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(image, cmap=\"inferno\")\n",
    "        plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the training images\n",
    "X_train = icebergs[['band_1', 'band_2']]\n",
    "# Remove the first row (column names)\n",
    "column_names = X_train.iloc[0]\n",
    "X_train = X_train.iloc[1:]\n",
    "\n",
    "column_1 = np.array([np.array(image) for image in X_train['band_1']])\n",
    "column_2 = np.array([np.array(image) for image in X_train['band_2']])\n",
    "\n",
    "column_1 = column_1.flatten().reshape(-1)\n",
    "column_2 = column_2.flatten().reshape(-1)\n",
    "\n",
    "mean_1 = np.mean(column_1)\n",
    "std_1 = np.std(column_1)\n",
    "\n",
    "mean_2 = np.mean(column_2)\n",
    "std_2 = np.std(column_2)\n",
    "\n",
    "normalized_column_1 = (column_1 - column_1.min()) / (column_1.max() - column_1.min())\n",
    "normalized_column_2 = (column_2 - column_2.min()) / (column_2.max() - column_2.min())\n",
    "#normalized_column_1 = (column_1 - mean_1) / std_1\n",
    "#normalized_column_2 = (column_2 - mean_2) / std_2\n",
    "\n",
    "X_train_normalized = np.column_stack((normalized_column_1, normalized_column_2))\n",
    "#print(X_train[0])\n",
    "# Reshape images \n",
    "X_train = X_train_normalized.reshape(-1, WIDTH,HEIGHT,CHANNELS)\n",
    "\n",
    "# Convert X_train to a NumPy array\n",
    "X_train_array = np.array(X_train)\n",
    "\n",
    "\n",
    "print(X_train_array.shape)\n",
    "\n",
    "# create batches of tensors to be fed into the model\n",
    "dataset = X_train\n",
    "print(X_train_array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator_dcgan():\n",
    "    model = Sequential([\n",
    "        Dense(25 * 25 * 256, input_dim=NOISE_DIM),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Reshape((25, 25, 256)),\n",
    "        \n",
    "        Conv2DTranspose(32, (2, 2), strides=(3, 3), padding='valid'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "\n",
    "        Conv2DTranspose(64, (2, 2), strides=(1, 1), padding='valid'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        \n",
    "        Conv2DTranspose(128, (2, 2), strides=(1, 1), padding='valid'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "\n",
    "        Conv2D(2, (3, 3), padding='valid', activation='tanh')\n",
    "    ], name=\"generator\")\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=OPTIMIZER)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator_dcgan():\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (3, 3), padding='same', input_shape=(75, 75, 2)),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "\n",
    "        Conv2D(75, (3, 3), strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "\n",
    "        Conv2D(75, (3, 3), strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "\n",
    "        Conv2D(75, (3, 3), strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "\n",
    "        Flatten(),\n",
    "        Dropout(0.4),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ], name=\"discriminator\")\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=OPTIMIZER)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n')\n",
    "discriminator_dcgan = build_discriminator_dcgan()\n",
    "print('\\n')\n",
    "generator_dcgan = build_generator_dcgan()\n",
    "trainable_discriminator_vars = discriminator_dcgan.trainable_variables\n",
    "trainable_generator_vars = generator_dcgan.trainable_variables\n",
    "trainable_vars = trainable_discriminator_vars + trainable_generator_vars\n",
    "OPTIMIZER.build(trainable_vars)\n",
    "\n",
    "discriminator_dcgan.trainable = False \n",
    "\n",
    "gan_input = Input(shape=(NOISE_DIM,))\n",
    "fake_image = generator_dcgan(gan_input)\n",
    "print(fake_image.shape)\n",
    "dcgan_output = discriminator_dcgan(fake_image)\n",
    "\n",
    "dcgan = Model(gan_input, dcgan_output, name=\"gan_model\")\n",
    "dcgan.compile(loss=\"binary_crossentropy\", optimizer=OPTIMIZER)\n",
    "\n",
    "#print(\"The Combined Network:\\n\")\n",
    "#gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Generator Model\n",
    "def build_generator_wgan():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(18 * 18 * 256, use_bias=False, input_shape=(75 * 75 * 2,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((18, 18, 256)))\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(2, (4, 4), strides=(1, 1), padding='valid', use_bias=False, activation='tanh'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Critic Model\n",
    "def build_critic_wgan():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[75, 75, 2]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define the loss function for the critic\n",
    "def critic_loss(real_output, fake_output):\n",
    "    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "\n",
    "# Define the loss function for the generator\n",
    "def generator_loss(fake_output):\n",
    "    return -tf.reduce_mean(fake_output)\n",
    "\n",
    "# Gradient penalty function\n",
    "def gradient_penalty(critic, real_images, fake_images):\n",
    "    BATCH_SIZE = tf.shape(real_images)[0]\n",
    "    alpha = tf.random.uniform(shape=[BATCH_SIZE, 1, 1, 1], minval=0.0, maxval=1.0)\n",
    "    real_images = tf.cast(real_images, tf.float32)\n",
    "    interpolated_images = real_images[:BATCH_SIZE] + alpha * (fake_images[:BATCH_SIZE] - real_images[:BATCH_SIZE])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(interpolated_images)\n",
    "        critic_interpolated = critic(interpolated_images)\n",
    "\n",
    "    gradients = tape.gradient(critic_interpolated, interpolated_images)\n",
    "    gradients_norm = tf.norm(gradients)\n",
    "    gradient_penalty = tf.reduce_mean((gradients_norm - 1.0) ** 2)\n",
    "\n",
    "    return gradient_penalty\n",
    "\n",
    "\n",
    "# Training loop\n",
    "def train_wgan(images, epochs=100, batch_size=64, critic_steps=5):\n",
    "    # Normalize the input images to the range [-1, 1]\n",
    "    images = (images - 0.5) * 2.0\n",
    "\n",
    "    generator = build_generator_wgan()\n",
    "    critic = build_critic_wgan()\n",
    "\n",
    "    # Define the optimizers for the generator and critic\n",
    "    generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    critic_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(images):\n",
    "        for i in range(critic_steps):\n",
    "            # Generate random noise as input to the generator\n",
    "            noise = tf.random.normal([batch_size, 75*75*2])\n",
    "            print('critic range', i)\n",
    "            with tf.GradientTape() as critic_tape:\n",
    "                # Generate fake images from the noise using the generator\n",
    "                generated_images = generator(noise)\n",
    "\n",
    "                # Get the critic's output for real and fake images\n",
    "                real_output = critic(images)\n",
    "                fake_output = critic(generated_images)\n",
    "\n",
    "                # Compute the critic loss and the gradient penalty\n",
    "                critic_loss_value = critic_loss(real_output, fake_output)\n",
    "                gp = gradient_penalty(critic, images, generated_images)\n",
    "                total_loss = critic_loss_value + 10.0 * gp\n",
    "\n",
    "            # Compute the gradients and update the critic's parameters\n",
    "            critic_gradients = critic_tape.gradient(total_loss, critic.trainable_variables)\n",
    "            critic_optimizer.apply_gradients(zip(critic_gradients, critic.trainable_variables))\n",
    "\n",
    "        # Generate random noise as input to the generator\n",
    "        noise = tf.random.normal([batch_size, 75*75*2])\n",
    "\n",
    "        with tf.GradientTape() as generator_tape:\n",
    "            # Generate fake images from the noise using the generator\n",
    "            generated_images = generator(noise)\n",
    "\n",
    "            # Get the critic's output for the generated images\n",
    "            fake_output = critic(generated_images)\n",
    "\n",
    "            # Compute the generator loss\n",
    "            generator_loss_value = generator_loss(fake_output)\n",
    "\n",
    "        # Compute the gradients and update the generator's parameters\n",
    "        generator_gradients = generator_tape.gradient(generator_loss_value, generator.trainable_variables)\n",
    "        generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
    "\n",
    "        return critic_loss_value, generator_loss_value\n",
    "\n",
    "    # Create a dataset from the input images\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(images).shuffle(len(images)).batch(batch_size)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        print(epoch)\n",
    "        for image_batch in dataset:\n",
    "            critic_loss_value, generator_loss_value = train_step(image_batch)\n",
    "\n",
    "        # Print the losses for monitoring the training progress\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Critic Loss: {critic_loss_value:.4f}, Generator Loss: {generator_loss_value:.4f}\")\n",
    "\n",
    "    return generator\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have an array of images called 'input_images' with shape (num_images, 75, 75, 2)\n",
    "input_images = X_train\n",
    "print(input_images.shape)\n",
    "generator_wgan = train_wgan(input_images, epochs=5, batch_size=32, critic_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 75, 2)\n",
      "(75, 75, 2)\n",
      "oxe\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\flopes1\\AppData\\Local\\Temp\\ipykernel_52376\\4003475053.py\", line 63, in train_step  *\n        real_output = discriminator(tf.concat([input_images, target_images], axis=-1), training=True)\n    File \"C:\\Users\\flopes1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\flopes1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_47\" is incompatible with the layer: expected shape=(None, 75, 75, 4), found shape=(75, 75, 4)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[138], line 98\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39m# Create dataset with input and target images\u001b[39;00m\n\u001b[0;32m     97\u001b[0m dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensor_slices((input_images, X_train_array))\n\u001b[1;32m---> 98\u001b[0m train(dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[138], line 84\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mprint\u001b[39m(input_images\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     83\u001b[0m \u001b[39mprint\u001b[39m(target_images\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> 84\u001b[0m train_step(input_images, target_images)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file6uh8s15x.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[1;34m(input_images, target_images)\u001b[0m\n\u001b[0;32m      9\u001b[0m generated_images \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(generator), (ag__\u001b[39m.\u001b[39mld(X_train_array),), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), fscope)\n\u001b[0;32m     10\u001b[0m ag__\u001b[39m.\u001b[39mld(\u001b[39mprint\u001b[39m)(\u001b[39m'\u001b[39m\u001b[39moxe\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m real_output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(discriminator), (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mconcat, ([ag__\u001b[39m.\u001b[39;49mld(input_images), ag__\u001b[39m.\u001b[39;49mld(target_images)],), \u001b[39mdict\u001b[39;49m(axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m), fscope),), \u001b[39mdict\u001b[39;49m(training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m), fscope)\n\u001b[0;32m     12\u001b[0m fake_output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(discriminator), (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mconcat, ([ag__\u001b[39m.\u001b[39mld(input_images), ag__\u001b[39m.\u001b[39mld(generated_images)],), \u001b[39mdict\u001b[39m(axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), fscope),), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), fscope)\n\u001b[0;32m     13\u001b[0m disc_loss \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(discriminator_loss), (ag__\u001b[39m.\u001b[39mld(real_output), ag__\u001b[39m.\u001b[39mld(fake_output)), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\input_spec.py:295\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[39mif\u001b[39;00m spec_dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m     \u001b[39mif\u001b[39;00m spec_dim \u001b[39m!=\u001b[39m dim:\n\u001b[1;32m--> 295\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    296\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m is \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    297\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mincompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected shape=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    299\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfound shape=\u001b[39m\u001b[39m{\u001b[39;00mdisplay_shape(x\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    300\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\flopes1\\AppData\\Local\\Temp\\ipykernel_52376\\4003475053.py\", line 63, in train_step  *\n        real_output = discriminator(tf.concat([input_images, target_images], axis=-1), training=True)\n    File \"C:\\Users\\flopes1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\flopes1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_47\" is incompatible with the layer: expected shape=(None, 75, 75, 4), found shape=(75, 75, 4)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Generator model\n",
    "def build_generator_pix2pix():\n",
    "    inputs = tf.keras.Input(shape=(75, 75, 2))\n",
    "\n",
    "    # Encoder\n",
    "    down1 = layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same')(inputs)\n",
    "    down2 = layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same')(layers.LeakyReLU()(down1))\n",
    "    \n",
    "    # Decoder\n",
    "    up1 = layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(layers.LeakyReLU()(down2))\n",
    "    up2 = layers.Conv2DTranspose(2, (3, 3), strides=(2, 2), padding='same')(layers.LeakyReLU()(up1))\n",
    "\n",
    "    # Output\n",
    "    outputs = layers.Activation('tanh')(up2)\n",
    "    return models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Discriminator model\n",
    "def build_discriminator_pix2pix():\n",
    "    inputs = tf.keras.Input(shape=(75, 75, 4))\n",
    "\n",
    "    # Convolutional layers\n",
    "    conv1 = layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same')(inputs)\n",
    "    conv2 = layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same')(layers.LeakyReLU()(conv1))\n",
    "    conv3 = layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same')(layers.LeakyReLU()(conv2))\n",
    "    \n",
    "    # Classification layer\n",
    "    outputs = layers.Conv2D(1, (3, 3), strides=(1, 1), padding='same')(layers.LeakyReLU()(conv3))\n",
    "\n",
    "    return models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Define the loss functions\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# Discriminator loss function\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "# Generator loss function\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "# Optimizers for generator and discriminator\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "# Initialize generator and discriminator models\n",
    "generator = build_generator_pix2pix()\n",
    "discriminator = build_discriminator_pix2pix()\n",
    "# Training loop\n",
    "@tf.function\n",
    "def train_step(input_images, target_images):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # Generate fake images\n",
    "        generated_images = generator(X_train_array, training=True)\n",
    "        print('oxe')\n",
    "        # Discriminator loss\n",
    "        real_output = discriminator(tf.concat([input_images, target_images], axis=-1), training=True)\n",
    "        fake_output = discriminator(tf.concat([input_images, generated_images], axis=-1), training=True)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "        # Generator loss\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "\n",
    "    # Calculate gradients and apply them\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "# Training loop\n",
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for input_images, target_images in dataset:\n",
    "            train_step(input_images, target_images)\n",
    "\n",
    "\n",
    "# Define a function to split the paired images into input and target images\n",
    "def split_images(real_image, target_image):\n",
    "    return real_image, target_image\n",
    "\n",
    "# Assuming X_train_array has shape (num_samples, 75, 75, 2)\n",
    "num_samples = X_train_array.shape[0]\n",
    "# Generate random noise as input images\n",
    "input_images = np.random.normal(size=(num_samples, 75, 75, 2))\n",
    "\n",
    "# Create dataset with input and target images\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_images, X_train_array))\n",
    "train(dataset, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(noise, subplots, generator, prefix, figsize=(22,8), save=False):\n",
    "    generated_images = generator.predict(noise)\n",
    "    plt.figure(figsize=figsize)\n",
    "    #print(np.amax(generated_images))\n",
    "    for i, image in enumerate(generated_images):\n",
    "        plt.subplot(subplots[0], subplots[1], i+1)\n",
    "        if CHANNELS == 1:\n",
    "            plt.imshow(image.reshape((WIDTH, HEIGHT)), cmap='gray')    \n",
    "                                                                            \n",
    "        else:\n",
    "            image_band1 = np.reshape(np.array(image[:, :, 1]),(75,75))\n",
    "            plt.imshow(image_band1, cmap='inferno')\n",
    "\n",
    "            #channel_1 = image[:, :, 0]\n",
    "            #channel_2 = image[:, :, 1]\n",
    "\n",
    "            #plt.subplot(1, 2, 1)\n",
    "            #plt.imshow(channel_1, cmap='gray')\n",
    "            #plt.title('Channel 1')\n",
    "\n",
    "            #plt.subplot(1, 2, 2)\n",
    "            #plt.imshow(channel_2, cmap='gray')\n",
    "            #plt.title('Channel 2')\n",
    "\n",
    "            #plt.show()\n",
    "            import matplotlib.image\n",
    "            #print(np.amin(image.reshape((WIDTH, HEIGHT, 3))))\n",
    "            from skimage import util\n",
    "            #image = (image - image.min()) / (image.max() - image.min())\n",
    "            #print(np.min(image))   # minimum value of the image data\n",
    "            #print(np.max(image))   # maximum value of the image data\n",
    "            #matplotlib.image.imsave('gen_img'+str(i)+'.png', image)\n",
    "            #image_data = np.transpose(image, (2, 0, 1))\n",
    "            # Transpose the array to have shape (height, width, num_channels)\n",
    "            #image_data = np.transpose(image, (2, 0, 1))\n",
    "            #print(image.shape)\n",
    "            # Concatenate the channels along the third axis to create a multi-channel image\n",
    "            print(image.shape)\n",
    "            joined_channels_image = np.concatenate([np.expand_dims(image[:, :, i], axis=0) for i in range(image.shape[2])], axis=0)\n",
    "            plt.imshow(joined_channels_image)\n",
    "            # Save grayscale image as PNG\n",
    "            plt.imsave(prefix + '_gen_img' + str(i) + '.png', joined_channels_image, cmap='inferno')\n",
    "\n",
    "        if save == True:\n",
    "            img_name = \"gen\" + str(i)\n",
    "            plt.savefig(img_name)\n",
    "        plt.subplots_adjust(wspace=None, hspace=None)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "for epoch in range(100):\n",
    "    \n",
    "    for batch in tqdm(range(10)):\n",
    "\n",
    "        noise = np.random.normal(0,1, size=(BATCH_SIZE, NOISE_DIM))\n",
    "        fake_X = generator_dcgan.predict(noise)\n",
    "        \n",
    "        idx = np.random.randint(0, X_train_array.shape[0], size=BATCH_SIZE)\n",
    "        real_X = X_train_array[idx]\n",
    "        X = np.concatenate((real_X, fake_X))\n",
    "\n",
    "        disc_y = np.zeros(2*BATCH_SIZE)\n",
    "        disc_y[:BATCH_SIZE] = 1\n",
    "\n",
    "        d_loss = discriminator_dcgan.train_on_batch(X, disc_y)\n",
    "        \n",
    "        y_gen = np.ones(BATCH_SIZE)\n",
    "        g_loss = dcgan.train_on_batch(noise, y_gen)\n",
    "\n",
    "    print(f\"EPOCH: {epoch + 1} Generator Loss: {g_loss:.4f} Discriminator Loss: {d_loss:.4f}\")\n",
    "    noise = np.random.normal(0, 1, size=(BATCH_SIZE,NOISE_DIM))\n",
    "    #sample_images(noise, (2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noise = np.random.normal(0, 1, size=(100, NOISE_DIM))\n",
    "noise = tf.random.normal([32, 75*75*2])\n",
    "sample_images(noise, (10,10), generator_dcgan, 'dcgan', (24,20), save=True)\n",
    "sample_images(noise, (10,10), generator_wgan, 'wgan', (24,20), save=True)\n",
    "sample_images(noise, (10,10), generator_pix2pix, 'pix2pix', (24,20), save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
